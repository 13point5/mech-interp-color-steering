{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Token Log Probability Analysis for Color Steering\n",
        "\n",
        "This notebook analyzes the token log probability distribution shifts when applying activation steering for color preferences, following the methodology from the activation addition paper.\n",
        "\n",
        "We will:\n",
        "1. Extract token log probabilities for baseline and steered models\n",
        "2. Calculate mean log probability differences across tokens\n",
        "3. Generate distribution shift plots (Q-Q plot style)\n",
        "4. Find tokens with greatest absolute change in log probability\n",
        "5. Analyze results across different layers and steering strengths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/mech-interp-color-steering/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from collections import defaultdict\n",
        "import json\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Import our color steering class\n",
        "from color_steering_actadd import ColorSteering\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration for analysis\n",
        "MODEL_NAME = \"Qwen/Qwen3-8B\"\n",
        "\n",
        "# Define the layers and strengths to analyze\n",
        "LAYERS_TO_ANALYZE = [3]  # Adjust based on your findings\n",
        "STRENGTHS_TO_ANALYZE = [2, 4]  # Adjust based on your experiments\n",
        "\n",
        "# Define experiments to analyze\n",
        "EXPERIMENTS = {\n",
        "\t\t\"yellow_neutral\": {\n",
        "\t\t\t\"name\": \"Yellow vs Neutral Colors\",\n",
        "\t\t\t\"positive_prompt\": \"ALWAYS USE HTML code with yellow hex colors like #FFFF00, #FFD700, #F0E68C. Your favorite theme color for websites is yellow\",\n",
        "\t\t\t\"negative_prompt\": \"ALWAYS USE HTML code with colors of your choice.\"\n",
        "\t\t},\n",
        "\t\t\"red_neutral\": {\n",
        "\t\t\t\"name\": \"Red vs Neutral Colors\",\n",
        "\t\t\t\"positive_prompt\": \"ALWAYS USE HTML code with red hex colors like #FF0000, #800000, #FF7F7F. Your favorite theme color for websites is red\",\n",
        "\t\t\t\"negative_prompt\": \"ALWAYS USE HTML code with colors of your choice.\"\n",
        "\t\t},\n",
        "\t\t\"green_neutral\": {\n",
        "\t\t\t\"name\": \"Green vs Neutral Colors\",\n",
        "\t\t\t\"positive_prompt\": \"ALWAYS USE HTML code with green hex colors like #00FF00, #008000, #00FF7F. Your favorite theme color for websites is green\",\n",
        "\t\t\t\"negative_prompt\": \"ALWAYS USE HTML code with colors of your choice.\"\n",
        "\t\t},\n",
        "\t\t\"pink_neutral\": {\n",
        "\t\t\t\"name\": \"Pink vs Neutral Colors\",\n",
        "\t\t\t\"positive_prompt\": \"ALWAYS USE HTML code with pink hex colors like #FFC0CB, #FFB6C1, #FF69B4. Your favorite theme color for websites is pink\",\n",
        "\t\t\t\"negative_prompt\": \"ALWAYS USE HTML code with colors of your choice.\"\n",
        "\t\t},\n",
        "\t\t\"blue_neutral\": {\n",
        "\t\t\t\"name\": \"Blue vs Neutral Colors\",\n",
        "\t\t\t\"positive_prompt\": \"ALWAYS USE HTML code with blue hex colors like #0000FF, #4169E1, #87CEEB. Your favorite theme color for websites is blue\",\n",
        "\t\t\t\"negative_prompt\": \"ALWAYS USE HTML code with colors of your choice.\"\n",
        "\t\t},\n",
        "\t\t\"orange_neutral\": {\n",
        "\t\t\t\"name\": \"Orange vs Neutral Colors\",\n",
        "\t\t\t\"positive_prompt\": \"ALWAYS USE HTML code with orange hex colors like #FFA500, #FF8C00, #FF7F50. Your favorite theme color for websites is orange\",\n",
        "\t\t\t\"negative_prompt\": \"ALWAYS USE HTML code with colors of your choice.\"\n",
        "\t\t},\n",
        "}\n",
        "\n",
        "# Test prompts for analysis\n",
        "TEST_PROMPTS = [\n",
        "    \"Generate a website for a modern SaaS company\",\n",
        "    # \"Create a homepage for a local bakery\",\n",
        "    # \"Design a website for a fitness studio\"\n",
        "]\n",
        "\n",
        "# System prompt\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are an expert website designer and software engineer.\n",
        "\n",
        "You will be given a request to generate a website.\n",
        "\n",
        "You need to produce a single HTML file that can be used as a website.\n",
        "Rules to follow:\n",
        "- The output should only be the HTML code. No other text or comments. No code blocks like ```html.\n",
        "- The code should contain all the HTML, CSS, and JavaScript needed to build the website.\n",
        "- Only use valid hex codes for colors.\n",
        "- The website should be colorful and modern.\n",
        "\"\"\"\n",
        "\n",
        "# Number of tokens to analyze for log probability differences\n",
        "MAX_TOKENS_TO_ANALYZE = 3000 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model...\n",
            "Using device: cuda\n",
            "Loading model: Qwen/Qwen3-8B\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 5/5 [00:03<00:00,  1.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded on: cuda:0\n",
            "Tokenizer pad_token_id: 151645\n",
            "Model has 36 transformer layers\n",
            "Model loaded with 36 layers\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Initialize the color steering model\n",
        "print(\"Loading model...\")\n",
        "steerer = ColorSteering(MODEL_NAME)\n",
        "print(f\"Model loaded with {steerer.num_layers} layers\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Full Vocabulary Log Probability Analysis\n",
        "\n",
        "For a comprehensive analysis like in the paper, we'll compute log probabilities for the entire vocabulary at each position.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_with_logprob_tracking(steerer, prompt, steering_vector=None, steering_layer=None, max_new_tokens=3000):\n",
        "    \"\"\"\n",
        "    Generate tokens while tracking log probabilities at each step.\n",
        "    \n",
        "    This does autoregressive generation and captures the log probability distribution\n",
        "    at each generation step, which is what we need for the analysis.\n",
        "    \n",
        "    Args:\n",
        "        steerer: ColorSteering instance\n",
        "        prompt: Input prompt\n",
        "        steering_vector: Steering vector to apply (None for baseline)\n",
        "        steering_layer: Layer to apply steering at (None for baseline)\n",
        "        max_new_tokens: Number of new tokens to generate\n",
        "    \n",
        "    Returns:\n",
        "        logprobs_per_step: List of log probability arrays, one per generation step\n",
        "        generated_tokens: List of generated token IDs\n",
        "    \"\"\"\n",
        "    # Apply chat template\n",
        "    formatted_prompt = steerer._apply_chat_template_with_thinking_disabled(prompt)\n",
        "    \n",
        "    # Tokenize\n",
        "    inputs = steerer.tokenizer(formatted_prompt, return_tensors='pt', padding=True)\n",
        "    inputs = {k: v.to(next(steerer.model.parameters()).device) for k, v in inputs.items()}\n",
        "    \n",
        "    # Set up steering hook if needed\n",
        "    handle = None\n",
        "    if steering_vector is not None and steering_layer is not None:\n",
        "        def steering_hook(module, layer_inputs):\n",
        "            resid_pre, = layer_inputs\n",
        "            if resid_pre.shape[1] == 1:\n",
        "                return None  # Skip for single token steps during generation\n",
        "            \n",
        "            ppos, apos = resid_pre.shape[1], steering_vector.shape[1]\n",
        "            if apos <= ppos:\n",
        "                modified_resid = resid_pre.clone()\n",
        "                modified_resid[:, :apos, :] += steering_vector\n",
        "                \n",
        "                if torch.isnan(modified_resid).any() or torch.isinf(modified_resid).any():\n",
        "                    return resid_pre\n",
        "                \n",
        "                return modified_resid\n",
        "            return resid_pre\n",
        "        \n",
        "        handle = steerer.blocks[steering_layer].register_forward_pre_hook(steering_hook)\n",
        "    \n",
        "    logprobs_per_step = []\n",
        "    generated_tokens = []\n",
        "    \n",
        "    try:\n",
        "        with torch.no_grad():\n",
        "            current_input_ids = inputs['input_ids'].clone()\n",
        "            current_attention_mask = inputs['attention_mask'].clone()\n",
        "            \n",
        "            for step in range(max_new_tokens):\n",
        "                # Forward pass\n",
        "                outputs = steerer.model(\n",
        "                    input_ids=current_input_ids,\n",
        "                    attention_mask=current_attention_mask\n",
        "                )\n",
        "                \n",
        "                # Get logits for the last position (next token prediction)\n",
        "                logits = outputs.logits[0, -1, :]  # [vocab_size]\n",
        "                log_probs = torch.log_softmax(logits, dim=-1)\n",
        "                logprobs_per_step.append(log_probs.cpu().numpy())\n",
        "                \n",
        "                # Sample next token (using temperature for diversity)\n",
        "                probs = torch.softmax(logits / 0.7, dim=-1)\n",
        "                next_token = torch.multinomial(probs, 1)\n",
        "                generated_tokens.append(next_token.item())\n",
        "                \n",
        "                # Stop if we hit EOS token\n",
        "                if next_token.item() == steerer.tokenizer.eos_token_id:\n",
        "                    print(f\"    Hit EOS at step {step}\")\n",
        "                    break\n",
        "                \n",
        "                # Update inputs for next iteration\n",
        "                current_input_ids = torch.cat([current_input_ids, next_token.unsqueeze(0)], dim=1)\n",
        "                current_attention_mask = torch.cat([\n",
        "                    current_attention_mask,\n",
        "                    torch.ones(1, 1, device=current_attention_mask.device)\n",
        "                ], dim=1)\n",
        "                \n",
        "                # Progress indicator\n",
        "                if step % 500 == 0 and step > 0:\n",
        "                    print(f\"    Generated {step} tokens...\")\n",
        "    \n",
        "    finally:\n",
        "        if handle is not None:\n",
        "            handle.remove()\n",
        "    \n",
        "    return np.array(logprobs_per_step), generated_tokens\n",
        "\n",
        "\n",
        "def get_full_vocab_logprobs_comparison(steerer, prompt, steering_vector, steering_layer, max_new_tokens=3000):\n",
        "    \"\"\"\n",
        "    Compare log probabilities between baseline and steered models during generation.\n",
        "    \n",
        "    This generates max_new_tokens tokens for both baseline and steered models,\n",
        "    capturing the full vocabulary log probabilities at each generation step.\n",
        "    \n",
        "    Args:\n",
        "        steerer: ColorSteering instance\n",
        "        prompt: Input prompt\n",
        "        steering_vector: Steering vector\n",
        "        steering_layer: Layer to apply steering at\n",
        "        max_new_tokens: Number of tokens to generate (uses MAX_TOKENS_TO_ANALYZE)\n",
        "    \n",
        "    Returns:\n",
        "        Dict with baseline_logprobs and steered_logprobs arrays\n",
        "    \"\"\"\n",
        "    print(f\"  Generating {max_new_tokens} tokens for baseline...\")\n",
        "    baseline_logprobs, baseline_tokens = generate_with_logprob_tracking(\n",
        "        steerer, prompt, max_new_tokens=max_new_tokens\n",
        "    )\n",
        "    \n",
        "    print(f\"  Generating {max_new_tokens} tokens for steered model (layer {steering_layer})...\")\n",
        "    steered_logprobs, steered_tokens = generate_with_logprob_tracking(\n",
        "        steerer, prompt, steering_vector, steering_layer, max_new_tokens=max_new_tokens\n",
        "    )\n",
        "    \n",
        "    print(f\"  Baseline generated {len(baseline_tokens)} tokens\")\n",
        "    print(f\"  Steered generated {len(steered_tokens)} tokens\")\n",
        "    \n",
        "    return {\n",
        "        'baseline_logprobs': baseline_logprobs,    # Shape: [generation_steps, vocab_size]\n",
        "        'steered_logprobs': steered_logprobs,      # Shape: [generation_steps, vocab_size]\n",
        "        'baseline_tokens': baseline_tokens,\n",
        "        'steered_tokens': steered_tokens\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_document_perplexity_shift(baseline_logprobs, steered_logprobs, baseline_tokens, steered_tokens, tokenizer, top_k=20):\n",
        "    \"\"\"\n",
        "    Analyze the shift in document-level perplexity, following the paper's methodology.\n",
        "    \n",
        "    The paper computes:\n",
        "    1. Mean log-probability L̄(d, M) for each document d under model M\n",
        "    2. The difference L̄(d, M_steered) - L̄(d, M_baseline) \n",
        "    3. Groups documents and analyzes the distribution of these differences\n",
        "    \n",
        "    For the token-level analysis, we also look at which tokens have the greatest\n",
        "    absolute change in log probability across all generation steps.\n",
        "    \"\"\"\n",
        "    print(f\"    Baseline shape: {baseline_logprobs.shape}\")\n",
        "    print(f\"    Steered shape: {steered_logprobs.shape}\")\n",
        "    \n",
        "    # Find the minimum number of positions to compare\n",
        "    min_positions = min(baseline_logprobs.shape[0], steered_logprobs.shape[0])\n",
        "    print(f\"    Analyzing first {min_positions} positions\")\n",
        "    \n",
        "    # === DOCUMENT-LEVEL ANALYSIS (like the paper) ===\n",
        "    # Compute mean log-probability for each document (generation sequence)\n",
        "    baseline_truncated = baseline_logprobs[:min_positions, :]\n",
        "    steered_truncated = steered_logprobs[:min_positions, :]\n",
        "    \n",
        "    # Get the actual log probabilities of the generated tokens\n",
        "    baseline_actual_logprobs = []\n",
        "    steered_actual_logprobs = []\n",
        "    \n",
        "    for i in range(min_positions):\n",
        "        # Get log prob of the token that was actually generated\n",
        "        baseline_token = baseline_tokens[i]\n",
        "        steered_token = steered_tokens[i]\n",
        "        \n",
        "        baseline_actual_logprobs.append(baseline_truncated[i, baseline_token])\n",
        "        steered_actual_logprobs.append(steered_truncated[i, steered_token])\n",
        "    \n",
        "    # Document-level mean log probabilities (like L̄(d, M) in the paper)\n",
        "    baseline_doc_mean_logprob = np.mean(baseline_actual_logprobs)\n",
        "    steered_doc_mean_logprob = np.mean(steered_actual_logprobs)\n",
        "    \n",
        "    # The key metric from the paper: difference in document mean log-prob\n",
        "    doc_logprob_diff = steered_doc_mean_logprob - baseline_doc_mean_logprob\n",
        "    \n",
        "    print(f\"    Document perplexity analysis:\")\n",
        "    print(f\"      Baseline mean log-prob: {baseline_doc_mean_logprob:.4f}\")\n",
        "    print(f\"      Steered mean log-prob: {steered_doc_mean_logprob:.4f}\")\n",
        "    print(f\"      Difference: {doc_logprob_diff:.4f}\")\n",
        "    print(f\"      Perplexity ratio: {np.exp(-doc_logprob_diff):.4f}\")\n",
        "    \n",
        "    # === TOKEN-LEVEL ANALYSIS (for the distribution shift plot) ===\n",
        "    # Calculate mean log probability difference for each token across all positions\n",
        "    mean_logprob_diff = np.mean(steered_truncated - baseline_truncated, axis=0)\n",
        "    mean_logprob_baseline = np.mean(baseline_truncated, axis=0)\n",
        "    \n",
        "    # === TOP CHANGED TOKENS ANALYSIS (like Table 11 in the paper) ===\n",
        "    # The paper shows tokens with greatest absolute change, but focuses on meaningful tokens\n",
        "    # Let's look at tokens that either:\n",
        "    # 1. Were actually generated by either model, OR\n",
        "    # 2. Have significant probability mass in either model\n",
        "    \n",
        "    # Get all tokens that were actually generated\n",
        "    all_generated_tokens = set(baseline_tokens[:min_positions] + steered_tokens[:min_positions])\n",
        "    \n",
        "    # Also include tokens with high probability in either model at any position\n",
        "    # (to catch important tokens that might not have been sampled)\n",
        "    high_prob_threshold = -5.0  # log prob > -5.0 means prob > ~0.007\n",
        "    high_prob_tokens = set()\n",
        "    \n",
        "    for pos in range(min_positions):\n",
        "        # Find tokens with high probability in baseline\n",
        "        high_baseline = np.where(baseline_truncated[pos, :] > high_prob_threshold)[0]\n",
        "        high_prob_tokens.update(high_baseline)\n",
        "        \n",
        "        # Find tokens with high probability in steered\n",
        "        high_steered = np.where(steered_truncated[pos, :] > high_prob_threshold)[0]\n",
        "        high_prob_tokens.update(high_steered)\n",
        "    \n",
        "    # Combine generated tokens and high-probability tokens\n",
        "    relevant_tokens = all_generated_tokens.union(high_prob_tokens)\n",
        "    print(f\"    Analyzing {len(relevant_tokens)} relevant tokens (generated + high probability)\")\n",
        "    \n",
        "    # Get the changes for only these relevant tokens\n",
        "    relevant_changes = []\n",
        "    for token_id in relevant_tokens:\n",
        "        relevant_changes.append({\n",
        "            'token_id': token_id,\n",
        "            'mean_logprob_diff': mean_logprob_diff[token_id],\n",
        "            'mean_logprob_baseline': mean_logprob_baseline[token_id],\n",
        "            'abs_change': abs(mean_logprob_diff[token_id])\n",
        "        })\n",
        "    \n",
        "    # Sort by absolute change and take top k\n",
        "    relevant_changes.sort(key=lambda x: x['abs_change'], reverse=True)\n",
        "    top_relevant_changes = relevant_changes[:top_k]\n",
        "    \n",
        "    # Create results table with decoded tokens\n",
        "    results = []\n",
        "    for change_data in top_relevant_changes:\n",
        "        token_id = change_data['token_id']\n",
        "        token = tokenizer.decode([token_id])\n",
        "        results.append({\n",
        "            'token': token,\n",
        "            'token_id': token_id,\n",
        "            'mean_logprob_diff': change_data['mean_logprob_diff'],\n",
        "            'mean_logprob_baseline': change_data['mean_logprob_baseline'],\n",
        "            'abs_change': change_data['abs_change']\n",
        "        })\n",
        "    \n",
        "    return {\n",
        "        # Document-level metrics (main result like the paper)\n",
        "        'doc_baseline_mean_logprob': baseline_doc_mean_logprob,\n",
        "        'doc_steered_mean_logprob': steered_doc_mean_logprob,\n",
        "        'doc_logprob_diff': doc_logprob_diff,\n",
        "        'perplexity_ratio': np.exp(-doc_logprob_diff),\n",
        "        \n",
        "        # Token-level metrics (for distribution analysis)\n",
        "        'mean_logprob_diff': mean_logprob_diff,\n",
        "        'mean_logprob_baseline': mean_logprob_baseline,\n",
        "        'top_changed_tokens': results,\n",
        "        'distribution_shift_data': mean_logprob_diff,\n",
        "        'positions_analyzed': min_positions,\n",
        "        'baseline_total_tokens': baseline_logprobs.shape[0],\n",
        "        'steered_total_tokens': steered_logprobs.shape[0]\n",
        "    }\n",
        "\n",
        "\n",
        "def plot_distribution_shift(mean_logprob_diff, title=\"Distribution Shift\", figsize=(10, 6)):\n",
        "    \"\"\"\n",
        "    Create a Q-Q plot style visualization of the distribution shift.\n",
        "    \"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
        "    \n",
        "    # Q-Q plot against normal distribution\n",
        "    stats.probplot(mean_logprob_diff, dist=\"norm\", plot=ax1)\n",
        "    ax1.set_title(f\"{title}\\nQ-Q Plot vs Normal Distribution\")\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Histogram of changes\n",
        "    ax2.hist(mean_logprob_diff, bins=50, alpha=0.7, density=True, color='blue')\n",
        "    ax2.axvline(0, color='red', linestyle='--', alpha=0.7, label='No change')\n",
        "    ax2.set_xlabel('Mean Log-Probability Difference')\n",
        "    ax2.set_ylabel('Density')\n",
        "    ax2.set_title(f\"{title}\\nDistribution of Changes\")\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "\n",
        "def plot_top_changed_tokens(top_tokens_data, title=\"Top Changed Tokens\", figsize=(12, 8)):\n",
        "    \"\"\"\n",
        "    Plot the tokens with the greatest absolute change in log probability.\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame(top_tokens_data)\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    \n",
        "    # Create bar plot\n",
        "    colors = ['red' if x < 0 else 'blue' for x in df['mean_logprob_diff']]\n",
        "    bars = ax.barh(range(len(df)), df['mean_logprob_diff'], color=colors, alpha=0.7)\n",
        "    \n",
        "    # Customize plot\n",
        "    ax.set_yticks(range(len(df)))\n",
        "    ax.set_yticklabels([f\"'{token}'\" for token in df['token']], fontsize=10)\n",
        "    ax.set_xlabel('Mean Log-Probability Difference')\n",
        "    ax.set_title(title)\n",
        "    ax.axvline(0, color='black', linestyle='-', alpha=0.3)\n",
        "    ax.grid(True, alpha=0.3, axis='x')\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for i, (bar, val) in enumerate(zip(bars, df['mean_logprob_diff'])):\n",
        "        ax.text(val + (0.01 if val >= 0 else -0.01), i, f'{val:.3f}', \n",
        "                va='center', ha='left' if val >= 0 else 'right', fontsize=8)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    return fig\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting log probability analysis...\n",
            "Will analyze 6 experiments × 1 layers × 2 strengths × 1 prompts\n",
            "Total combinations: 12\n"
          ]
        }
      ],
      "source": [
        "# Storage for all results\n",
        "all_analysis_results = {}\n",
        "\n",
        "# Create output directory\n",
        "output_dir = Path(\"logprob_analysis_results\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "print(\"Starting log probability analysis...\")\n",
        "print(f\"Will analyze {len(EXPERIMENTS)} experiments × {len(LAYERS_TO_ANALYZE)} layers × {len(STRENGTHS_TO_ANALYZE)} strengths × {len(TEST_PROMPTS)} prompts\")\n",
        "print(f\"Total combinations: {len(EXPERIMENTS) * len(LAYERS_TO_ANALYZE) * len(STRENGTHS_TO_ANALYZE) * len(TEST_PROMPTS)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Analyzing Experiment: Yellow vs Neutral Colors ===\n",
            "\n",
            "--- Layer 3 ---\n",
            "\n",
            "-- Strength 2 --\n",
            "Creating steering vector for layer 3\n",
            "Using positive prompt: ALWAYS USE HTML code with yellow hex colors like #FFFF00, #FFD700, #F0E68C. Your favorite theme color for websites is yellow\n",
            "Using negative prompt: ALWAYS USE HTML code with colors of your choice.\n",
            "- Analyzing prompt 1: Generate a website for a modern SaaS company...\n",
            "  Generating 3000 tokens for baseline...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Generated 1500 tokens...\n",
            "    Hit EOS at step 1516\n",
            "  Generating 3000 tokens for steered model (layer 3)...\n",
            "    Generated 500 tokens...\n",
            "    Hit EOS at step 959\n",
            "  Baseline generated 1517 tokens\n",
            "  Steered generated 960 tokens\n",
            "    Baseline shape: (1517, 151936)\n",
            "    Steered shape: (960, 151936)\n",
            "    Analyzing first 960 positions\n",
            "    Document perplexity analysis:\n",
            "      Baseline mean log-prob: -0.0546\n",
            "      Steered mean log-prob: -0.0844\n",
            "      Difference: -0.0298\n",
            "      Perplexity ratio: 1.0303\n",
            "    Analyzing 381 relevant tokens (generated + high probability)\n",
            "  Analysis summary:\n",
            "    Positions analyzed: 960\n",
            "    Baseline total tokens: 1517\n",
            "    Steered total tokens: 960\n",
            "    Document perplexity ratio: 1.0303\n",
            "  Top 5 increased tokens:\n",
            "    '>E': 6.0312\n",
            "    ' <': 5.9492\n",
            "    '</': 5.9023\n",
            "    ' </': 5.8125\n",
            "    '.</': 5.5430\n",
            "  Top 5 decreased tokens:\n",
            "\n",
            "-- Strength 4 --\n",
            "Creating steering vector for layer 3\n",
            "Using positive prompt: ALWAYS USE HTML code with yellow hex colors like #FFFF00, #FFD700, #F0E68C. Your favorite theme color for websites is yellow\n",
            "Using negative prompt: ALWAYS USE HTML code with colors of your choice.\n",
            "- Analyzing prompt 1: Generate a website for a modern SaaS company...\n",
            "  Generating 3000 tokens for baseline...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Generated 1500 tokens...\n",
            "    Hit EOS at step 1665\n",
            "  Generating 3000 tokens for steered model (layer 3)...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Hit EOS at step 1071\n",
            "  Baseline generated 1666 tokens\n",
            "  Steered generated 1072 tokens\n",
            "    Baseline shape: (1666, 151936)\n",
            "    Steered shape: (1072, 151936)\n",
            "    Analyzing first 1072 positions\n",
            "    Document perplexity analysis:\n",
            "      Baseline mean log-prob: -0.0670\n",
            "      Steered mean log-prob: -0.0874\n",
            "      Difference: -0.0204\n",
            "      Perplexity ratio: 1.0205\n",
            "    Analyzing 466 relevant tokens (generated + high probability)\n",
            "  Analysis summary:\n",
            "    Positions analyzed: 1072\n",
            "    Baseline total tokens: 1666\n",
            "    Steered total tokens: 1072\n",
            "    Document perplexity ratio: 1.0205\n",
            "  Top 5 increased tokens:\n",
            "    '?</': 4.2578\n",
            "    '</': 4.0898\n",
            "    ' <': 4.0859\n",
            "    ' </': 3.9453\n",
            "    '.</': 3.8203\n",
            "  Top 5 decreased tokens:\n",
            "\n",
            "=== Analyzing Experiment: Red vs Neutral Colors ===\n",
            "\n",
            "--- Layer 3 ---\n",
            "\n",
            "-- Strength 2 --\n",
            "Creating steering vector for layer 3\n",
            "Using positive prompt: ALWAYS USE HTML code with red hex colors like #FF0000, #800000, #FF7F7F. Your favorite theme color for websites is red\n",
            "Using negative prompt: ALWAYS USE HTML code with colors of your choice.\n",
            "- Analyzing prompt 1: Generate a website for a modern SaaS company...\n",
            "  Generating 3000 tokens for baseline...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Generated 1500 tokens...\n",
            "    Hit EOS at step 1589\n",
            "  Generating 3000 tokens for steered model (layer 3)...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Hit EOS at step 1207\n",
            "  Baseline generated 1590 tokens\n",
            "  Steered generated 1208 tokens\n",
            "    Baseline shape: (1590, 151936)\n",
            "    Steered shape: (1208, 151936)\n",
            "    Analyzing first 1208 positions\n",
            "    Document perplexity analysis:\n",
            "      Baseline mean log-prob: -0.0867\n",
            "      Steered mean log-prob: -0.0864\n",
            "      Difference: 0.0003\n",
            "      Perplexity ratio: 0.9995\n",
            "    Analyzing 488 relevant tokens (generated + high probability)\n",
            "  Analysis summary:\n",
            "    Positions analyzed: 1208\n",
            "    Baseline total tokens: 1590\n",
            "    Steered total tokens: 1208\n",
            "    Document perplexity ratio: 0.9995\n",
            "  Top 5 increased tokens:\n",
            "    '           ': 4.8594\n",
            "    ' <': 4.4336\n",
            "    '>\n",
            "\n",
            "': 4.1211\n",
            "    '?</': 4.0195\n",
            "    '</': 3.9766\n",
            "  Top 5 decreased tokens:\n",
            "\n",
            "-- Strength 4 --\n",
            "Creating steering vector for layer 3\n",
            "Using positive prompt: ALWAYS USE HTML code with red hex colors like #FF0000, #800000, #FF7F7F. Your favorite theme color for websites is red\n",
            "Using negative prompt: ALWAYS USE HTML code with colors of your choice.\n",
            "- Analyzing prompt 1: Generate a website for a modern SaaS company...\n",
            "  Generating 3000 tokens for baseline...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Hit EOS at step 1231\n",
            "  Generating 3000 tokens for steered model (layer 3)...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Hit EOS at step 1313\n",
            "  Baseline generated 1232 tokens\n",
            "  Steered generated 1314 tokens\n",
            "    Baseline shape: (1232, 151936)\n",
            "    Steered shape: (1314, 151936)\n",
            "    Analyzing first 1232 positions\n",
            "    Document perplexity analysis:\n",
            "      Baseline mean log-prob: -0.0795\n",
            "      Steered mean log-prob: -0.0988\n",
            "      Difference: -0.0193\n",
            "      Perplexity ratio: 1.0195\n",
            "    Analyzing 615 relevant tokens (generated + high probability)\n",
            "  Analysis summary:\n",
            "    Positions analyzed: 1232\n",
            "    Baseline total tokens: 1232\n",
            "    Steered total tokens: 1314\n",
            "    Document perplexity ratio: 1.0195\n",
            "  Top 5 increased tokens:\n",
            "    'FF': 3.0156\n",
            "    'FFFFFF': 2.8848\n",
            "    'AAAA': 2.8496\n",
            "    'CCCCCC': 2.8125\n",
            "    ' grid': 2.5840\n",
            "  Top 5 decreased tokens:\n",
            "\n",
            "=== Analyzing Experiment: Green vs Neutral Colors ===\n",
            "\n",
            "--- Layer 3 ---\n",
            "\n",
            "-- Strength 2 --\n",
            "Creating steering vector for layer 3\n",
            "Using positive prompt: ALWAYS USE HTML code with green hex colors like #00FF00, #008000, #00FF7F. Your favorite theme color for websites is green\n",
            "Using negative prompt: ALWAYS USE HTML code with colors of your choice.\n",
            "- Analyzing prompt 1: Generate a website for a modern SaaS company...\n",
            "  Generating 3000 tokens for baseline...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Hit EOS at step 1294\n",
            "  Generating 3000 tokens for steered model (layer 3)...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Hit EOS at step 1083\n",
            "  Baseline generated 1295 tokens\n",
            "  Steered generated 1084 tokens\n",
            "    Baseline shape: (1295, 151936)\n",
            "    Steered shape: (1084, 151936)\n",
            "    Analyzing first 1084 positions\n",
            "    Document perplexity analysis:\n",
            "      Baseline mean log-prob: -0.0784\n",
            "      Steered mean log-prob: -0.0793\n",
            "      Difference: -0.0009\n",
            "      Perplexity ratio: 1.0010\n",
            "    Analyzing 539 relevant tokens (generated + high probability)\n",
            "  Analysis summary:\n",
            "    Positions analyzed: 1084\n",
            "    Baseline total tokens: 1295\n",
            "    Steered total tokens: 1084\n",
            "    Document perplexity ratio: 1.0010\n",
            "  Top 5 increased tokens:\n",
            "    'Green': 4.9688\n",
            "    ' Green': 4.7930\n",
            "    ' green': 4.2305\n",
            "    '>E': 4.0430\n",
            "    'Leaf': 3.8984\n",
            "  Top 5 decreased tokens:\n",
            "\n",
            "-- Strength 4 --\n",
            "Creating steering vector for layer 3\n",
            "Using positive prompt: ALWAYS USE HTML code with green hex colors like #00FF00, #008000, #00FF7F. Your favorite theme color for websites is green\n",
            "Using negative prompt: ALWAYS USE HTML code with colors of your choice.\n",
            "- Analyzing prompt 1: Generate a website for a modern SaaS company...\n",
            "  Generating 3000 tokens for baseline...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Generated 1500 tokens...\n",
            "    Hit EOS at step 1514\n",
            "  Generating 3000 tokens for steered model (layer 3)...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Hit EOS at step 1218\n",
            "  Baseline generated 1515 tokens\n",
            "  Steered generated 1219 tokens\n",
            "    Baseline shape: (1515, 151936)\n",
            "    Steered shape: (1219, 151936)\n",
            "    Analyzing first 1219 positions\n",
            "    Document perplexity analysis:\n",
            "      Baseline mean log-prob: -0.1060\n",
            "      Steered mean log-prob: -0.0660\n",
            "      Difference: 0.0400\n",
            "      Perplexity ratio: 0.9609\n",
            "    Analyzing 497 relevant tokens (generated + high probability)\n",
            "  Analysis summary:\n",
            "    Positions analyzed: 1219\n",
            "    Baseline total tokens: 1515\n",
            "    Steered total tokens: 1219\n",
            "    Document perplexity ratio: 0.9609\n",
            "  Top 5 increased tokens:\n",
            "    '?</': 2.1582\n",
            "    '</': 2.0312\n",
            "    ' <': 1.9570\n",
            "    'Green': 1.8809\n",
            "    '.</': 1.8789\n",
            "  Top 5 decreased tokens:\n",
            "    '1': -1.6465\n",
            "    '6': -1.6064\n",
            "    '3': -1.4922\n",
            "    '5': -1.4922\n",
            "    '4': -1.4814\n",
            "\n",
            "=== Analyzing Experiment: Pink vs Neutral Colors ===\n",
            "\n",
            "--- Layer 3 ---\n",
            "\n",
            "-- Strength 2 --\n",
            "Creating steering vector for layer 3\n",
            "Using positive prompt: ALWAYS USE HTML code with pink hex colors like #FFC0CB, #FFB6C1, #FF69B4. Your favorite theme color for websites is pink\n",
            "Using negative prompt: ALWAYS USE HTML code with colors of your choice.\n",
            "- Analyzing prompt 1: Generate a website for a modern SaaS company...\n",
            "  Generating 3000 tokens for baseline...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Hit EOS at step 1372\n",
            "  Generating 3000 tokens for steered model (layer 3)...\n",
            "    Generated 500 tokens...\n",
            "    Hit EOS at step 909\n",
            "  Baseline generated 1373 tokens\n",
            "  Steered generated 910 tokens\n",
            "    Baseline shape: (1373, 151936)\n",
            "    Steered shape: (910, 151936)\n",
            "    Analyzing first 910 positions\n",
            "    Document perplexity analysis:\n",
            "      Baseline mean log-prob: -0.0585\n",
            "      Steered mean log-prob: -0.0945\n",
            "      Difference: -0.0360\n",
            "      Perplexity ratio: 1.0371\n",
            "    Analyzing 452 relevant tokens (generated + high probability)\n",
            "  Analysis summary:\n",
            "    Positions analyzed: 910\n",
            "    Baseline total tokens: 1373\n",
            "    Steered total tokens: 910\n",
            "    Document perplexity ratio: 1.0371\n",
            "  Top 5 increased tokens:\n",
            "    '?</': 5.6719\n",
            "    '</': 5.2344\n",
            "    ' <': 5.1953\n",
            "    '.</': 5.1406\n",
            "    ' </': 5.1367\n",
            "  Top 5 decreased tokens:\n",
            "\n",
            "-- Strength 4 --\n",
            "Creating steering vector for layer 3\n",
            "Using positive prompt: ALWAYS USE HTML code with pink hex colors like #FFC0CB, #FFB6C1, #FF69B4. Your favorite theme color for websites is pink\n",
            "Using negative prompt: ALWAYS USE HTML code with colors of your choice.\n",
            "- Analyzing prompt 1: Generate a website for a modern SaaS company...\n",
            "  Generating 3000 tokens for baseline...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Generated 1500 tokens...\n",
            "    Hit EOS at step 1860\n",
            "  Generating 3000 tokens for steered model (layer 3)...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Hit EOS at step 1030\n",
            "  Baseline generated 1861 tokens\n",
            "  Steered generated 1031 tokens\n",
            "    Baseline shape: (1861, 151936)\n",
            "    Steered shape: (1031, 151936)\n",
            "    Analyzing first 1031 positions\n",
            "    Document perplexity analysis:\n",
            "      Baseline mean log-prob: -0.0824\n",
            "      Steered mean log-prob: -0.1025\n",
            "      Difference: -0.0201\n",
            "      Perplexity ratio: 1.0205\n",
            "    Analyzing 550 relevant tokens (generated + high probability)\n",
            "  Analysis summary:\n",
            "    Positions analyzed: 1031\n",
            "    Baseline total tokens: 1861\n",
            "    Steered total tokens: 1031\n",
            "    Document perplexity ratio: 1.0205\n",
            "  Top 5 increased tokens:\n",
            "    '</': 4.6758\n",
            "    '?</': 4.6719\n",
            "    ' <': 4.5820\n",
            "    ' </': 4.3516\n",
            "    '.</': 4.2148\n",
            "  Top 5 decreased tokens:\n",
            "\n",
            "=== Analyzing Experiment: Blue vs Neutral Colors ===\n",
            "\n",
            "--- Layer 3 ---\n",
            "\n",
            "-- Strength 2 --\n",
            "Creating steering vector for layer 3\n",
            "Using positive prompt: ALWAYS USE HTML code with blue hex colors like #0000FF, #4169E1, #87CEEB. Your favorite theme color for websites is blue\n",
            "Using negative prompt: ALWAYS USE HTML code with colors of your choice.\n",
            "- Analyzing prompt 1: Generate a website for a modern SaaS company...\n",
            "  Generating 3000 tokens for baseline...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Hit EOS at step 1319\n",
            "  Generating 3000 tokens for steered model (layer 3)...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Hit EOS at step 1309\n",
            "  Baseline generated 1320 tokens\n",
            "  Steered generated 1310 tokens\n",
            "    Baseline shape: (1320, 151936)\n",
            "    Steered shape: (1310, 151936)\n",
            "    Analyzing first 1310 positions\n",
            "    Document perplexity analysis:\n",
            "      Baseline mean log-prob: -0.0822\n",
            "      Steered mean log-prob: -0.0634\n",
            "      Difference: 0.0188\n",
            "      Perplexity ratio: 0.9814\n",
            "    Analyzing 586 relevant tokens (generated + high probability)\n",
            "  Analysis summary:\n",
            "    Positions analyzed: 1310\n",
            "    Baseline total tokens: 1320\n",
            "    Steered total tokens: 1310\n",
            "    Document perplexity ratio: 0.9814\n",
            "  Top 5 increased tokens:\n",
            "    '           ': 2.7207\n",
            "    'FFFFFF': 1.7246\n",
            "    '       ': 1.5713\n",
            "    'FF': 1.3574\n",
            "    '               ': 1.3359\n",
            "  Top 5 decreased tokens:\n",
            "    '     ': -2.9199\n",
            "    '   ': -1.5361\n",
            "    ' --': -1.4170\n",
            "    '--': -1.3711\n",
            "    '—': -1.0674\n",
            "\n",
            "-- Strength 4 --\n",
            "Creating steering vector for layer 3\n",
            "Using positive prompt: ALWAYS USE HTML code with blue hex colors like #0000FF, #4169E1, #87CEEB. Your favorite theme color for websites is blue\n",
            "Using negative prompt: ALWAYS USE HTML code with colors of your choice.\n",
            "- Analyzing prompt 1: Generate a website for a modern SaaS company...\n",
            "  Generating 3000 tokens for baseline...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Hit EOS at step 1293\n",
            "  Generating 3000 tokens for steered model (layer 3)...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Hit EOS at step 1191\n",
            "  Baseline generated 1294 tokens\n",
            "  Steered generated 1192 tokens\n",
            "    Baseline shape: (1294, 151936)\n",
            "    Steered shape: (1192, 151936)\n",
            "    Analyzing first 1192 positions\n",
            "    Document perplexity analysis:\n",
            "      Baseline mean log-prob: -0.0980\n",
            "      Steered mean log-prob: -0.0978\n",
            "      Difference: 0.0002\n",
            "      Perplexity ratio: 1.0000\n",
            "    Analyzing 662 relevant tokens (generated + high probability)\n",
            "  Analysis summary:\n",
            "    Positions analyzed: 1192\n",
            "    Baseline total tokens: 1294\n",
            "    Steered total tokens: 1192\n",
            "    Document perplexity ratio: 1.0000\n",
            "  Top 5 increased tokens:\n",
            "    '           ': 2.7402\n",
            "    '.</': 2.0508\n",
            "    ' experience': 1.8740\n",
            "    ' </': 1.8477\n",
            "    '</': 1.7930\n",
            "  Top 5 decreased tokens:\n",
            "    '     ': -2.8906\n",
            "\n",
            "=== Analyzing Experiment: Orange vs Neutral Colors ===\n",
            "\n",
            "--- Layer 3 ---\n",
            "\n",
            "-- Strength 2 --\n",
            "Creating steering vector for layer 3\n",
            "Using positive prompt: ALWAYS USE HTML code with orange hex colors like #FFA500, #FF8C00, #FF7F50. Your favorite theme color for websites is orange\n",
            "Using negative prompt: ALWAYS USE HTML code with colors of your choice.\n",
            "- Analyzing prompt 1: Generate a website for a modern SaaS company...\n",
            "  Generating 3000 tokens for baseline...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Hit EOS at step 1368\n",
            "  Generating 3000 tokens for steered model (layer 3)...\n",
            "    Generated 500 tokens...\n",
            "    Hit EOS at step 988\n",
            "  Baseline generated 1369 tokens\n",
            "  Steered generated 989 tokens\n",
            "    Baseline shape: (1369, 151936)\n",
            "    Steered shape: (989, 151936)\n",
            "    Analyzing first 989 positions\n",
            "    Document perplexity analysis:\n",
            "      Baseline mean log-prob: -0.0657\n",
            "      Steered mean log-prob: -0.0935\n",
            "      Difference: -0.0278\n",
            "      Perplexity ratio: 1.0283\n",
            "    Analyzing 458 relevant tokens (generated + high probability)\n",
            "  Analysis summary:\n",
            "    Positions analyzed: 989\n",
            "    Baseline total tokens: 1369\n",
            "    Steered total tokens: 989\n",
            "    Document perplexity ratio: 1.0283\n",
            "  Top 5 increased tokens:\n",
            "    '?</': 4.6289\n",
            "    '</': 4.4570\n",
            "    '           ': 4.3242\n",
            "    '.</': 4.2461\n",
            "    ' <': 4.2031\n",
            "  Top 5 decreased tokens:\n",
            "\n",
            "-- Strength 4 --\n",
            "Creating steering vector for layer 3\n",
            "Using positive prompt: ALWAYS USE HTML code with orange hex colors like #FFA500, #FF8C00, #FF7F50. Your favorite theme color for websites is orange\n",
            "Using negative prompt: ALWAYS USE HTML code with colors of your choice.\n",
            "- Analyzing prompt 1: Generate a website for a modern SaaS company...\n",
            "  Generating 3000 tokens for baseline...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Generated 1500 tokens...\n",
            "    Hit EOS at step 1517\n",
            "  Generating 3000 tokens for steered model (layer 3)...\n",
            "    Generated 500 tokens...\n",
            "    Generated 1000 tokens...\n",
            "    Hit EOS at step 1153\n",
            "  Baseline generated 1518 tokens\n",
            "  Steered generated 1154 tokens\n",
            "    Baseline shape: (1518, 151936)\n",
            "    Steered shape: (1154, 151936)\n",
            "    Analyzing first 1154 positions\n",
            "    Document perplexity analysis:\n",
            "      Baseline mean log-prob: -0.0555\n",
            "      Steered mean log-prob: -0.0766\n",
            "      Difference: -0.0211\n",
            "      Perplexity ratio: 1.0215\n",
            "    Analyzing 434 relevant tokens (generated + high probability)\n",
            "  Analysis summary:\n",
            "    Positions analyzed: 1154\n",
            "    Baseline total tokens: 1518\n",
            "    Steered total tokens: 1154\n",
            "    Document perplexity ratio: 1.0215\n",
            "  Top 5 increased tokens:\n",
            "    '           ': 3.9023\n",
            "    ' <': 3.1797\n",
            "    ' </': 3.0488\n",
            "    '?</': 3.0488\n",
            "    '</': 2.9395\n",
            "  Top 5 decreased tokens:\n",
            "    '     ': -2.5957\n",
            "\n",
            "Analysis complete!\n"
          ]
        }
      ],
      "source": [
        "# Run analysis for each combination\n",
        "for exp_key, experiment in EXPERIMENTS.items():\n",
        "    print(f\"\\n=== Analyzing Experiment: {experiment['name']} ===\")\n",
        "    \n",
        "    all_analysis_results[exp_key] = {}\n",
        "    \n",
        "    for layer in LAYERS_TO_ANALYZE:\n",
        "        print(f\"\\n--- Layer {layer} ---\")\n",
        "        all_analysis_results[exp_key][layer] = {}\n",
        "        \n",
        "        for strength in STRENGTHS_TO_ANALYZE:\n",
        "            print(f\"\\n-- Strength {strength} --\")\n",
        "            all_analysis_results[exp_key][layer][strength] = {}\n",
        "            \n",
        "            try:\n",
        "                # Create steering vector\n",
        "                steering_vector = steerer.create_steering_vector(\n",
        "                    experiment['positive_prompt'],\n",
        "                    experiment['negative_prompt'],\n",
        "                    layer,\n",
        "                    coeff=strength\n",
        "                )\n",
        "                \n",
        "                for prompt_idx, test_prompt in enumerate(TEST_PROMPTS):\n",
        "                    print(f\"- Analyzing prompt {prompt_idx + 1}: {test_prompt[:50]}...\")\n",
        "                    \n",
        "                    full_prompt = SYSTEM_PROMPT + \"\\n\\n\" + test_prompt\n",
        "                    \n",
        "                    try:\n",
        "                        # Get full vocabulary log probabilities comparison\n",
        "                        # Note: steering_vector was created for 'layer', so we steer at 'layer'\n",
        "                        # but measure the effect at the final output logits\n",
        "                        logprob_data = get_full_vocab_logprobs_comparison(\n",
        "                            steerer, full_prompt, steering_vector, steering_layer=layer, \n",
        "                            max_new_tokens=MAX_TOKENS_TO_ANALYZE\n",
        "                        )\n",
        "                        \n",
        "                        # Analyze distribution shift\n",
        "                        analysis_results = analyze_document_perplexity_shift(\n",
        "                            logprob_data['baseline_logprobs'],\n",
        "                            logprob_data['steered_logprobs'],\n",
        "                            logprob_data['baseline_tokens'],\n",
        "                            logprob_data['steered_tokens'],\n",
        "                            steerer.tokenizer,\n",
        "                            top_k=20\n",
        "                        )\n",
        "                        \n",
        "                        # Store results\n",
        "                        all_analysis_results[exp_key][layer][strength][prompt_idx] = {\n",
        "                            'analysis': analysis_results,\n",
        "                            'baseline_tokens': logprob_data['baseline_tokens'],\n",
        "                            'steered_tokens': logprob_data['steered_tokens'],\n",
        "                            'prompt': test_prompt\n",
        "                        }\n",
        "                        \n",
        "                        # Print analysis summary\n",
        "                        print(f\"  Analysis summary:\")\n",
        "                        print(f\"    Positions analyzed: {analysis_results['positions_analyzed']}\")\n",
        "                        print(f\"    Baseline total tokens: {analysis_results['baseline_total_tokens']}\")\n",
        "                        print(f\"    Steered total tokens: {analysis_results['steered_total_tokens']}\")\n",
        "                        print(f\"    Document perplexity ratio: {analysis_results['perplexity_ratio']:.4f}\")\n",
        "                        \n",
        "                        # Print top changed tokens\n",
        "                        print(f\"  Top 5 increased tokens:\")\n",
        "                        increased_tokens = [t for t in analysis_results['top_changed_tokens'] if t['mean_logprob_diff'] > 0][:5]\n",
        "                        for token_data in increased_tokens:\n",
        "                            print(f\"    '{token_data['token']}': {token_data['mean_logprob_diff']:.4f}\")\n",
        "                        \n",
        "                        print(f\"  Top 5 decreased tokens:\")\n",
        "                        decreased_tokens = [t for t in analysis_results['top_changed_tokens'] if t['mean_logprob_diff'] < 0][:5]\n",
        "                        for token_data in decreased_tokens:\n",
        "                            print(f\"    '{token_data['token']}': {token_data['mean_logprob_diff']:.4f}\")\n",
        "                        \n",
        "                    except Exception as e:\n",
        "                        print(f\"  Error analyzing prompt {prompt_idx}: {e}\")\n",
        "                        continue\n",
        "                        \n",
        "            except Exception as e:\n",
        "                print(f\"Error creating steering vector for layer {layer}, strength {strength}: {e}\")\n",
        "                continue\n",
        "\n",
        "print(\"\\nAnalysis complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating visualizations...\n",
            "\n",
            "Generating plots for Yellow vs Neutral Colors\n",
            "\n",
            "Generating plots for Red vs Neutral Colors\n",
            "\n",
            "Generating plots for Green vs Neutral Colors\n",
            "\n",
            "Generating plots for Pink vs Neutral Colors\n",
            "\n",
            "Generating plots for Blue vs Neutral Colors\n",
            "\n",
            "Generating plots for Orange vs Neutral Colors\n",
            "Visualizations saved!\n"
          ]
        }
      ],
      "source": [
        "# Generate plots for key results\n",
        "print(\"Generating visualizations...\")\n",
        "\n",
        "for exp_key, experiment in EXPERIMENTS.items():\n",
        "    print(f\"\\nGenerating plots for {experiment['name']}\")\n",
        "    \n",
        "    # Create experiment-specific output directory\n",
        "    exp_output_dir = output_dir / exp_key\n",
        "    exp_output_dir.mkdir(exist_ok=True)\n",
        "    \n",
        "    for layer in LAYERS_TO_ANALYZE:\n",
        "        for strength in STRENGTHS_TO_ANALYZE:\n",
        "            if layer not in all_analysis_results[exp_key] or strength not in all_analysis_results[exp_key][layer]:\n",
        "                continue\n",
        "                \n",
        "            for prompt_idx in range(len(TEST_PROMPTS)):\n",
        "                if prompt_idx not in all_analysis_results[exp_key][layer][strength]:\n",
        "                    continue\n",
        "                    \n",
        "                result_data = all_analysis_results[exp_key][layer][strength][prompt_idx]\n",
        "                analysis = result_data['analysis']\n",
        "                \n",
        "                # Plot distribution shift\n",
        "                title = f\"{experiment['name']} - Layer {layer}, Strength {strength}, Prompt {prompt_idx}\"\n",
        "                fig1 = plot_distribution_shift(\n",
        "                    analysis['distribution_shift_data'], \n",
        "                    title=title\n",
        "                )\n",
        "                fig1.savefig(exp_output_dir / f\"distribution_shift_L{layer}_S{strength}_P{prompt_idx}.png\", \n",
        "                           dpi=150, bbox_inches='tight')\n",
        "                plt.close(fig1)\n",
        "                \n",
        "                # Plot top changed tokens\n",
        "                fig2 = plot_top_changed_tokens(\n",
        "                    analysis['top_changed_tokens'],\n",
        "                    title=f\"Top Changed Tokens - {title}\"\n",
        "                )\n",
        "                fig2.savefig(exp_output_dir / f\"top_tokens_L{layer}_S{strength}_P{prompt_idx}.png\", \n",
        "                           dpi=150, bbox_inches='tight')\n",
        "                plt.close(fig2)\n",
        "\n",
        "print(\"Visualizations saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['analysis', 'baseline_tokens', 'steered_tokens', 'prompt'])\n"
          ]
        }
      ],
      "source": [
        "t_layer = 3\n",
        "t_strength = 2\n",
        "t_prompt_idx = 0\n",
        "res = all_analysis_results['red_neutral'][t_layer][t_strength][t_prompt_idx]\n",
        "print(res.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['doc_baseline_mean_logprob', 'doc_steered_mean_logprob', 'doc_logprob_diff', 'perplexity_ratio', 'mean_logprob_diff', 'mean_logprob_baseline', 'top_changed_tokens', 'distribution_shift_data', 'positions_analyzed', 'baseline_total_tokens', 'steered_total_tokens'])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res['analysis'].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-1.035, -1.237, -1.097, ..., -1.198, -1.198, -1.198],\n",
              "      shape=(151936,), dtype=float16)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res['analysis']['distribution_shift_data']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
